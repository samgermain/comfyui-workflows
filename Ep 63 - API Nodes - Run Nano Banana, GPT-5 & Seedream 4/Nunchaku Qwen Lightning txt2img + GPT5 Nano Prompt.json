{
  "id": "ded01669-c5db-4581-84d8-706b035da66a",
  "revision": 0,
  "last_node_id": 121,
  "last_link_id": 201,
  "nodes": [
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        901.5586547851562,
        147.01731872558594
      ],
      "size": [
        300,
        262
      ],
      "flags": {
        "collapsed": false
      },
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 125
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 46
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 139
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 192
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            128
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "KSampler",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        34297450039595,
        "randomize",
        4,
        1,
        "res_multistep",
        "simple",
        1
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1224.8416748046875,
        146.51097106933594
      ],
      "size": [
        210,
        46
      ],
      "flags": {
        "collapsed": false
      },
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 128
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 76
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            195
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAEDecode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": []
    },
    {
      "id": 115,
      "type": "NunchakuQwenImageDiTLoader",
      "pos": [
        -84.13290405273438,
        84.61837768554688
      ],
      "size": [
        494.162109375,
        130
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            196
          ]
        }
      ],
      "properties": {
        "aux_id": "mit-han-lab/ComfyUI-nunchaku",
        "ver": "1.0.1",
        "Node name for S&R": "NunchakuQwenImageDiTLoader",
        "cnr_id": "comfyui-nunchaku"
      },
      "widgets_values": [
        "svdq-int4_r32-qwen-image-lightningv1.0-4steps.safetensors",
        "auto",
        1,
        "disable"
      ]
    },
    {
      "id": 38,
      "type": "CLIPLoader",
      "pos": [
        -84.13290405273438,
        262.9801025390625
      ],
      "size": [
        494.162109375,
        106
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 0,
          "links": [
            187
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPLoader",
        "models": [
          {
            "name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "directory": "text_encoders"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "qwen_2.5_vl_7b_fp8_scaled.safetensors",
        "qwen_image",
        "default"
      ]
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        -84.13290405273438,
        417.341796875
      ],
      "size": [
        494.162109375,
        58
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [
            76
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "qwen_image_vae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors",
            "directory": "vae"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "qwen_image_vae.safetensors"
      ]
    },
    {
      "id": 78,
      "type": "ConditioningZeroOut",
      "pos": [
        696.596923828125,
        146.0343780517578
      ],
      "size": [
        197.712890625,
        26
      ],
      "flags": {
        "collapsed": true
      },
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 138
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            139
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.49",
        "Node name for S&R": "ConditioningZeroOut"
      },
      "widgets_values": []
    },
    {
      "id": 66,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        440.39508056640625,
        85.55369567871094
      ],
      "size": [
        229.08192443847656,
        58
      ],
      "flags": {
        "collapsed": false
      },
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 196
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            125
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "ModelSamplingAuraFlow",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        3
      ]
    },
    {
      "id": 75,
      "type": "MarkdownNote",
      "pos": [
        -692.814697265625,
        83.25602722167969
      ],
      "size": [
        589.99169921875,
        685.9707641601562
      ],
      "flags": {
        "collapsed": false
      },
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "üëë Pixaroma - Note - START HERE (Episode 62)",
      "properties": {},
      "widgets_values": [
        "# MODELS AND NODES USED IN THIS WORKFLOW  \n\n---\n\n### I used this Easy Installer for Portable ComfyUI from [HERE](https://github.com/Tavris1/ComfyUI-Easy-Install) after installing that you run the Nunchaku bat file from Addons folder.\n\n---\n\n## üü£ Nunchaku Qwen-Image DiT Loader\n\n## ‚ö†Ô∏è For Nvidia 40 series and lower, use INT4 models.\n## ‚ö†Ô∏è For the 50 series, use FP4 models.\n\n### Download **svdq-int4_r32-qwen-image-lightningv1.0-4steps.safetensors** from [HERE](https://huggingface.co/nunchaku-tech/nunchaku-qwen-image/resolve/main/svdq-int4_r32-qwen-image-lightningv1.0-4steps.safetensors?download=true) \n\n### Or a different version from [HERE](https://huggingface.co/nunchaku-tech/nunchaku-qwen-image/tree/main) depending on your video card\n\nüìÅ **Place in:** `ComfyUI/models/diffusion_models` \n\n---\n\n## üü£ Load CLIP\n\n###  Download **qwen_2.5_vl_7b_fp8_scaled.safetensors** from [HERE](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors) or a bigger model from [HERE](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/tree/main/split_files/text_encoders)\n\nüìÅ **Place in:** `ComfyUI/models/clip`  \n\n---\n\n## üü£ Load VAE\n\n### Download **qwen_image_vae.safetensors** vae model from [HERE](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors)  \n\nüìÅ **Place in:** `ComfyUI/models/vae`  \n\n---\n\n## üß© Nodes Installed from Manager  \n\n- **rgthree-comfy**\n- **ComfyUI-nunchaku**\n\n---\n\n## üìö Resources  \nüé• **Tutorials:** [Pixaroma YouTube Channel](https://www.youtube.com/@pixaroma)  \nüí¨ **Community Discord:** [Join Here](https://discord.com/invite/gggpkVgBf3)\n\nLearn more about Nunchaku Node from [HERE](https://github.com/nunchaku-tech/ComfyUI-nunchaku)\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 108,
      "type": "SaveImage",
      "pos": [
        1220.1668701171875,
        241.43057250976562
      ],
      "size": [
        485.80377197265625,
        511.6747741699219
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 195
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.50",
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": [
        "img"
      ]
    },
    {
      "id": 76,
      "type": "EmptySD3LatentImage",
      "pos": [
        652.6361694335938,
        533.0028076171875
      ],
      "size": [
        270,
        106
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            192
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.49",
        "Node name for S&R": "EmptySD3LatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        1
      ],
      "color": "#323",
      "bgcolor": "#535"
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        439.08184814453125,
        192.09458923339844
      ],
      "size": [
        430.9995422363281,
        240.29859924316406
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 187
        },
        {
          "name": "text",
          "type": "STRING",
          "widget": {
            "name": "text"
          },
          "link": 200
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            46,
            138
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        ""
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 120,
      "type": "OpenAIChatNode",
      "pos": [
        228.23297119140625,
        530.103515625
      ],
      "size": [
        362.9653015136719,
        580
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "shape": 7,
          "type": "IMAGE",
          "link": 198
        },
        {
          "name": "files",
          "shape": 7,
          "type": "OPENAI_INPUT_FILES",
          "link": null
        },
        {
          "name": "advanced_options",
          "shape": 7,
          "type": "OPENAI_CHAT_CONFIG",
          "link": 199
        }
      ],
      "outputs": [
        {
          "name": "STRING",
          "type": "STRING",
          "links": [
            200,
            201
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "OpenAIChatNode"
      },
      "widgets_values": [
        "Describe the uploaded image as a single, comma-separated text-to-image prompt that follows the system rules and returns only the prompt.\n",
        false,
        "gpt-5-nano",
        ""
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 121,
      "type": "PreviewAny",
      "pos": [
        616.353759765625,
        767.406982421875
      ],
      "size": [
        484.5436706542969,
        346.1452941894531
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "source",
          "type": "*",
          "link": 201
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "PreviewAny"
      },
      "widgets_values": []
    },
    {
      "id": 119,
      "type": "LoadImage",
      "pos": [
        -75.74776458740234,
        531.24609375
      ],
      "size": [
        290.0580749511719,
        397.1956481933594
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            198
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "woman 2.png",
        "image"
      ]
    },
    {
      "id": 118,
      "type": "OpenAIChatConfig",
      "pos": [
        -465.20074462890625,
        972.6925048828125
      ],
      "size": [
        673.2097778320312,
        384.7283020019531
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "OPENAI_CHAT_CONFIG",
          "type": "OPENAI_CHAT_CONFIG",
          "links": [
            199
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "OpenAIChatConfig"
      },
      "widgets_values": [
        "auto",
        4096,
        "You write one single text-to-image prompt that recreates the provided image as literally as possible.\n\nOutput rules:\n- Output only the prompt as one comma-separated line. No preface, no labels, no lists, no metadata, no quotes.\n- Do not invent or remove elements. If unsure, use neutral terms like \"unbranded\", \"unknown\".\n- No artist names, model names, camera brands, or quality boosters.\n- English only. Keep it concise and concrete.\n\nContent order to follow:\n1) main subject and clothing/accessories  \n2) background and setting (must explicitly state plain background or white seamless backdrop if seen)  \n3) composition and camera view (shot size, angle, depth of field)  \n4) lighting and shadows (type, direction, softness)  \n5) color palette and textures/materials  \n6) time of day or weather and mood (if visible)  \n7) visible text exactly as seen  \n8) medium or style only if clearly evident (photo, illustration, 3D render, watercolor, etc)\n\nTarget length: 150 words.\n"
      ]
    },
    {
      "id": 93,
      "type": "Label (rgthree)",
      "pos": [
        -692.814697265625,
        -1.9879130125045776
      ],
      "size": [
        955.7705078125,
        38
      ],
      "flags": {
        "allow_interaction": true
      },
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Nunchaku Qwen Lightning txt2img + GPT5 Nano Prompt",
      "properties": {
        "fontSize": 38,
        "fontFamily": "Arial",
        "fontColor": "#f8a742",
        "textAlign": "center",
        "backgroundColor": "transparent",
        "padding": 0,
        "borderRadius": 0
      },
      "color": "#fff0",
      "bgcolor": "#fff0"
    }
  ],
  "links": [
    [
      46,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      76,
      39,
      0,
      8,
      1,
      "VAE"
    ],
    [
      125,
      66,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      128,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      138,
      6,
      0,
      78,
      0,
      "CONDITIONING"
    ],
    [
      139,
      78,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      187,
      38,
      0,
      6,
      0,
      "CLIP"
    ],
    [
      192,
      76,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      195,
      8,
      0,
      108,
      0,
      "IMAGE"
    ],
    [
      196,
      115,
      0,
      66,
      0,
      "MODEL"
    ],
    [
      198,
      119,
      0,
      120,
      0,
      "IMAGE"
    ],
    [
      199,
      118,
      0,
      120,
      2,
      "OPENAI_CHAT_CONFIG"
    ],
    [
      200,
      120,
      0,
      6,
      1,
      "STRING"
    ],
    [
      201,
      120,
      0,
      121,
      0,
      "*"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.8390545288824214,
      "offset": [
        791.3024610354418,
        21.712834888744357
      ]
    },
    "frontendVersion": "1.26.11",
    "ue_links": [],
    "links_added_by_ue": [],
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}